{          
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtCRHk7d9pMK"
   },
   "source": [
    "# How to the TextVectorization Layer in TensorFLow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yV3XfcjY7Vb4"
   },
   "source": [
    "This video walks you through how to use the TextVectorization layer in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5pyat2_2uojp"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "L3RsgOluyiyU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 13:04:15.575246: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Instanting\n",
    "text_vectorization = TextVectorization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iY8S5onGytHD"
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    \"Bugun gunlerden cumartesi\",\n",
    "    \"Erdem, Ali, Ahmet ve Mehmet Parka gidecek\",\n",
    "    \"Aksam geri gelecekler\"\n",
    "    \"Yatip uyuyacaklar\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4ngXk1j4zCbb"
   },
   "outputs": [],
   "source": [
    "# Creating the vocabulary with the adapt method.\n",
    "text_vectorization.adapt(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05I_y-XVzKDl",
    "outputId": "3a62d4aa-b4f2-4d50-cced-b6f61fb1b09e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 've',\n",
       " 'uyuyacaklar',\n",
       " 'parka',\n",
       " 'mehmet',\n",
       " 'gunlerden',\n",
       " 'gidecek',\n",
       " 'geri',\n",
       " 'gelecekleryatip',\n",
       " 'erdem',\n",
       " 'cumartesi',\n",
       " 'bugun',\n",
       " 'ali',\n",
       " 'aksam',\n",
       " 'ahmet']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at the vocabulary.\n",
    "text_vectorization.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OEdicTg-zTQj",
    "outputId": "5a7a8e1e-31ca-4e50-fbd5-b996193eb0a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 7), dtype=int64, numpy=\n",
       "array([[12,  6, 11,  0,  0,  0,  0],\n",
       "       [10, 13, 15,  2,  5,  4,  7],\n",
       "       [14,  8,  9,  3,  0,  0,  0]])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data preprocessing with the layer\n",
    "vectorized_text = text_vectorization(data)\n",
    "vectorized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDU2o1dl7jI1"
   },
   "source": [
    "# Using the custom functions TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BGgSQArYzpvE"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aIx40gV406yD"
   },
   "outputs": [],
   "source": [
    "def standardization_fn(string_tensor):\n",
    "  lowercase=tf.strings.lower(string_tensor)\n",
    "  return tf.strings.regex_replace(\n",
    "      lowercase, f\"[{re.escape(string.punctuation)}]\", \"\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4T19MwA42RSq"
   },
   "outputs": [],
   "source": [
    "def split_fn(string_tensor):\n",
    "  return tf.strings.split(string_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "LwuWFbHC2qKT"
   },
   "outputs": [],
   "source": [
    "text_vectorization = TextVectorization(\n",
    "    standardize=standardization_fn,\n",
    "    split = split_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "GUlD9_573H9K"
   },
   "outputs": [],
   "source": [
    "text_vectorization.adapt(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AXmh5k_s3P_s",
    "outputId": "ba39b903-e28b-412e-fa10-53112277cee4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int64, numpy=array([12,  4,  7])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing our layer with a text\n",
    "text = \"bugun parka gidecek\"\n",
    "text_vectorization(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbTuG4QN8jtx"
   },
   "source": [
    "# Using TextVectorization in a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BPDzXpJW3wIq"
   },
   "outputs": [],
   "source": [
    "# Creating a Dataset object\n",
    "text_dataset = tf.data.Dataset.from_tensor_slices([\n",
    "    \"trabzonspor\", \"real_madrid\", \"alabama\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "PB6sAoHf4Ydq"
   },
   "outputs": [],
   "source": [
    "# Creating the TextVectorization layer\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=5000,\n",
    "    output_sequence_length=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5mqlU58R40P-"
   },
   "outputs": [],
   "source": [
    "# Creating the vocabulary\n",
    "vectorize_layer.adapt(text_dataset.batch(64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2sIxlLm-5RYq",
    "outputId": "1158826e-0f5c-427a-d143-25d2a7b7a895"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'trabzonspor', 'realmadrid', 'alabama']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "nAMORijK5WTC"
   },
   "outputs": [],
   "source": [
    "# Building the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(1,), dtype=tf.string),\n",
    "    vectorize_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZtqlDmjY5vx7"
   },
   "outputs": [],
   "source": [
    "# Getting a data for testing\n",
    "input_data=[[\"sampiyon trabzonspor\"], [\"winner real_madrid\"], [\"Sweet home alabama\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mISY78tN6AfL",
    "outputId": "711c2821-cc29-42c0-e991-9753fde97f92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 101ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 0, 0],\n",
       "       [1, 3, 0, 0],\n",
       "       [1, 1, 4, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(input_data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO9Zzm5eyUjAAYeJXfTbxU+",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
